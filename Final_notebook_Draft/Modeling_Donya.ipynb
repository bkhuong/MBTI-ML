{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MBTI Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "1- Make a combined notebook that is clean and easy to follow \n",
    "2- Add background information \n",
    "3- Visualize raw data (better plots than what have right now)\n",
    "4- Add parts about EDA (research to support it?)\n",
    "5- Compare the models visually \n",
    "6- What's the best model and why?\n",
    "7- Where can we go from here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string \n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General info:\n",
    "#### Personality Types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>processed_posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>moment    sportscenter top ten play    pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>finding lack post alarming  sex boring positi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>good one           course  say know  blessing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>dear     enjoyed conversation day   esoteric ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>fired  another silly misconception  approachi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  \\\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...   \n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...   \n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...   \n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...   \n",
       "4  ENTJ  'You're fired.|||That's another silly misconce...   \n",
       "\n",
       "                                     processed_posts  \n",
       "0       moment    sportscenter top ten play    pr...  \n",
       "1   finding lack post alarming  sex boring positi...  \n",
       "2   good one           course  say know  blessing...  \n",
       "3   dear     enjoyed conversation day   esoteric ...  \n",
       "4   fired  another silly misconception  approachi...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save time, run this to load the clean post\n",
    "processed_post = pd.read_csv('data/mbti_preprocessed_1.csv')\n",
    "processed_post.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "processed_post.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a bag of words representation of each user by using tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer\n",
    "vectorizer_tfidf = TfidfVectorizer(min_df=0.05, max_df=0.85, analyzer='word', ngram_range=(1, 2))\n",
    "word_tfidf = vectorizer_tfidf.fit_transform(processed_post['processed_posts'])\n",
    "word_tfidf_df = pd.DataFrame(data = word_tfidf.toarray(), columns = vectorizer_tfidf.get_feature_names())\n",
    "# CountVectorizer\n",
    "vectorizer_ct = CountVectorizer(stop_words='english',analyzer='word',input='content', \n",
    "                                 decode_error='ignore', max_df=0.48,min_df=5,\n",
    "                                 token_pattern=r'\\w{1,}', max_features=1625, ngram_range=(1,2)) # to compare two methods, I limit max_features=1625\n",
    "word_ct = vectorizer_ct.fit_transform(processed_post['processed_posts'])\n",
    "word_ct_df = pd.DataFrame(data = word_ct.toarray(), columns = vectorizer_ct.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abstract</th>\n",
       "      <th>accept</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>accurate</th>\n",
       "      <th>across</th>\n",
       "      <th>...</th>\n",
       "      <th>year ago</th>\n",
       "      <th>year old</th>\n",
       "      <th>yep</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.038307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.12246</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.071834</td>\n",
       "      <td>0.066683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1625 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability      able  absolute  absolutely  abstract  accept  according  \\\n",
       "0  0.00000  0.000000  0.000000    0.000000       0.0     0.0        0.0   \n",
       "1  0.00000  0.038307  0.000000    0.000000       0.0     0.0        0.0   \n",
       "2  0.12246  0.044400  0.000000    0.106856       0.0     0.0        0.0   \n",
       "3  0.00000  0.071834  0.066683    0.000000       0.0     0.0        0.0   \n",
       "4  0.00000  0.000000  0.000000    0.000000       0.0     0.0        0.0   \n",
       "\n",
       "   account  accurate  across    ...     year ago  year old       yep  \\\n",
       "0      0.0  0.000000     0.0    ...     0.067997  0.000000  0.083075   \n",
       "1      0.0  0.000000     0.0    ...     0.000000  0.000000  0.000000   \n",
       "2      0.0  0.064077     0.0    ...     0.000000  0.063801  0.000000   \n",
       "3      0.0  0.000000     0.0    ...     0.000000  0.000000  0.000000   \n",
       "4      0.0  0.000000     0.0    ...     0.000000  0.059121  0.000000   \n",
       "\n",
       "        yes  yesterday  yet  young  younger  youtube       yup  \n",
       "0  0.000000        0.0  0.0    0.0      0.0      0.0  0.000000  \n",
       "1  0.000000        0.0  0.0    0.0      0.0      0.0  0.000000  \n",
       "2  0.060355        0.0  0.0    0.0      0.0      0.0  0.081823  \n",
       "3  0.000000        0.0  0.0    0.0      0.0      0.0  0.000000  \n",
       "4  0.055929        0.0  0.0    0.0      0.0      0.0  0.000000  \n",
       "\n",
       "[5 rows x 1625 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word_tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbti = pd.read_csv(\"data/mbti_FE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(model, X, target, nsplits=4):\n",
    "    kf = StratifiedShuffleSplit(n_splits=nsplits, random_state=420)\n",
    "    \n",
    "    types = {'EorI':'Extroversion vs. Introversion', 'NorS': 'Intuition vs. Sensing',\n",
    "                 'TorF': 'Thinking vs. Feeling','JorP': 'Judging vs. Perceiving'}\n",
    "    t = time.time()\n",
    "    for col in target.columns:\n",
    "        print(f\"{types[col]}:\")\n",
    "        y = target[col]\n",
    "        all_auc = []\n",
    "        # all_accuracies = []\n",
    "        f_score = []\n",
    "        for train, test in kf.split(X,y):\n",
    "            X_train, X_test, y_train, y_test = X.loc[train], X.loc[test], y[train], y[test]\n",
    "            model.fit(X_train, y_train)\n",
    "            preds = model.predict(X_test)\n",
    "            # get the probability of prediction for auc score\n",
    "            preds_act = model.predict_proba(X_test)[:,1]\n",
    "            \n",
    "            # preds = model.predict(X_test)\n",
    "            auc = roc_auc_score(y_test, preds_act)\n",
    "            all_auc.append(auc)\n",
    "                    \n",
    "            fscore = f1_score(preds,y_test)\n",
    "            f_score.append(fscore)\n",
    "            model_name = str(model).split('(')[0]\n",
    "        print(f'Average AUC: {np.mean(all_auc):.3f}; Average fscore: {np.mean(f_score):.3f}')\n",
    "    print(f\"Time use:{time.time()-t:.3f}s\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizers and classifiers\n",
    "X_tf = pd.concat([mbti.iloc[:,6:],word_tfidf_df],axis=1)\n",
    "X_ct = pd.concat([mbti.iloc[:,6:],word_ct_df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extroversion vs. Introversion:\n",
      "Average AUC: 0.579; Average fscore: 0.017\n",
      "Intuition vs. Sensing:\n",
      "Average AUC: 0.539; Average fscore: 0.000\n",
      "Thinking vs. Feeling:\n",
      "Average AUC: 0.680; Average fscore: 0.568\n",
      "Judging vs. Perceiving:\n",
      "Average AUC: 0.501; Average fscore: 0.736\n",
      "Time use:163.062s\n"
     ]
    }
   ],
   "source": [
    "bagging = BaggingClassifier(KNeighborsClassifier(n_neighbors=10),\n",
    "                            max_samples=0.5, max_features=0.5)\n",
    "model(bagging, X_tf, target, nsplits=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extroversion vs. Introversion:\n",
      "Average AUC: 0.576; Average fscore: 0.045\n",
      "Intuition vs. Sensing:\n",
      "Average AUC: 0.567; Average fscore: 0.000\n",
      "Thinking vs. Feeling:\n",
      "Average AUC: 0.687; Average fscore: 0.565\n",
      "Judging vs. Perceiving:\n",
      "Average AUC: 0.559; Average fscore: 0.719\n",
      "Time use:550.821s\n"
     ]
    }
   ],
   "source": [
    "model(bagging, X_ct, target, nsplits=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "### Using TFIDF\n",
    "Works better than everything else!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extroversion vs. Introversion:\n",
      "Average AUC: 0.746; Average fscore: 0.261\n",
      "Intuition vs. Sensing:\n",
      "Average AUC: 0.746; Average fscore: 0.044\n",
      "Thinking vs. Feeling:\n",
      "Average AUC: 0.863; Average fscore: 0.760\n",
      "Judging vs. Perceiving:\n",
      "Average AUC: 0.712; Average fscore: 0.760\n",
      "Time use:26.775s\n"
     ]
    }
   ],
   "source": [
    "Logistic = LogisticRegression(random_state=0)\n",
    "model(Logistic, X_tf, target, nsplits=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extroversion vs. Introversion:\n",
      "Average AUC: 0.699; Average fscore: 0.424\n",
      "Intuition vs. Sensing:\n",
      "Average AUC: 0.680; Average fscore: 0.296\n",
      "Thinking vs. Feeling:\n",
      "Average AUC: 0.806; Average fscore: 0.712\n",
      "Judging vs. Perceiving:\n",
      "Average AUC: 0.676; Average fscore: 0.718\n",
      "Time use:40.883s\n"
     ]
    }
   ],
   "source": [
    "model(Logistic, X_ct, target, nsplits=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extroversion vs. Introversion:\n",
      "Average AUC: 0.538; Average fscore: 0.216\n",
      "Intuition vs. Sensing:\n",
      "Average AUC: 0.530; Average fscore: 0.099\n",
      "Thinking vs. Feeling:\n",
      "Average AUC: 0.601; Average fscore: 0.546\n",
      "Judging vs. Perceiving:\n",
      "Average AUC: 0.504; Average fscore: 0.633\n",
      "Time use:185.176s\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(gamma='auto')\n",
    "model(svm, X_ct, target, nsplits=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extroversion vs. Introversion:\n",
      "Average AUC: 0.718; Average fscore: 0.000\n",
      "Intuition vs. Sensing:\n",
      "Average AUC: 0.681; Average fscore: 0.000\n",
      "Thinking vs. Feeling:\n",
      "Average AUC: 0.825; Average fscore: 0.661\n",
      "Judging vs. Perceiving:\n",
      "Average AUC: 0.671; Average fscore: 0.753\n",
      "Time use:133.140s\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(random_state=0, n_estimators=300, max_depth=7)\n",
    "model(random_forest, X_tf, target, nsplits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extroversion vs. Introversion:\n",
      "Average AUC: 0.710; Average fscore: 0.000\n",
      "Intuition vs. Sensing:\n",
      "Average AUC: 0.673; Average fscore: 0.000\n",
      "Thinking vs. Feeling:\n",
      "Average AUC: 0.821; Average fscore: 0.617\n",
      "Judging vs. Perceiving:\n",
      "Average AUC: 0.674; Average fscore: 0.753\n",
      "Time use:97.837s\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(random_state=0, n_estimators=300, max_depth=5)\n",
    "model(random_forest, X_tf, target, nsplits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extroversion vs. Introversion:\n",
      "Average AUC: 0.703; Average fscore: 0.000\n",
      "Intuition vs. Sensing:\n",
      "Average AUC: 0.679; Average fscore: 0.000\n",
      "Thinking vs. Feeling:\n",
      "Average AUC: 0.807; Average fscore: 0.407\n",
      "Judging vs. Perceiving:\n",
      "Average AUC: 0.652; Average fscore: 0.753\n",
      "Time use:25.282s\n"
     ]
    }
   ],
   "source": [
    "model(random_forest, X_ct, target, nsplits=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
